{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c22fff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMake sure you have these installations to run the code. Add any if I missed anything.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Make sure you have these installations to run the code. Add any if I missed anything.\n",
    "'''\n",
    "# pip install notebook\n",
    "# pip install chardet\n",
    "# pip install tiktoken\n",
    "\n",
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71fac552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "import chardet\n",
    "import shutil\n",
    "import csv\n",
    "import spacy\n",
    "import string\n",
    "import tiktoken\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc7229c",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509dd43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove non_ascii text\n",
    "def remove_non_ascii(text):\n",
    "    for letter in text: \n",
    "        # Check if the character is not an ASCII character.\n",
    "        if letter.isascii() == False: \n",
    "            # Replace the non-ASCII character with an empty string, effectively removing it.\n",
    "            text = text.replace(letter, '')\n",
    "    \n",
    "    # Return the modified 'text' with non-ASCII characters removed.\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e7ee905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This store's the API key and has a function that creates a response from the created engine. \n",
    "To adjust finetuning outputs, edit this function.\n",
    "'''\n",
    "\n",
    "api_key = ...\n",
    "openai.api_key = api_key    \n",
    "    \n",
    "def create_response(prompt):\n",
    "    # Create a response using the specified engine, prompt, and parameters.\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"curie:ft-personal-2023-07-14-02-12-12\",  # create your own fine-tuning model\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,  # Adjust temperature for output randomness (0.7 is a reasonable value)\n",
    "        max_tokens=100,    # Limit the response to a maximum of 100 tokens\n",
    "        stop=\"END\"         # Specify a stopping condition for response generation\n",
    "    )\n",
    "    \n",
    "    # Extract and return the generated text from the API response.\n",
    "    return response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ebb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function is used to count tokens to check if a prompt exceeds the token limit - used in the test_files() function.\n",
    "'''\n",
    "\n",
    "def count_tokens(prompt):\n",
    "    # Load the spaCy English model (small version) for tokenization.\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # Tokenize the 'prompt' text using spaCy.\n",
    "    doc = nlp(prompt)\n",
    "    # Count the number of tokens in the tokenized text.\n",
    "    token_count = len(doc)\n",
    "    # Return the token count.\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4f2a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this cell, we are reading in my most recent version of ML Workflow - Data from my active directory (if working from another computer)\n",
    "the directory should be adjusted as necessary.  It gets all of the information we are looking for (train/test, grantor, grantee, program, date\n",
    "end date, amount, funding source, and text_id.)  Afterwards, we drop all columns with NA values in text_id. \n",
    "It clears the NaN values then sorts the testing and training data into separate dataframes.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Specify the path to the CSV file containing the data. Update this path as needed.\n",
    "ml = pd.read_csv(\"ML Workflow - Data.csv\")\n",
    "# Get desired columns from 'ml'\n",
    "ml = ml.get([\"Train/Test\", \"Grantor\", \"Grantee\", \"Program\", \"Date\", \"EndDate\", \"Amount\", \"Funding Source\", \"text_id\"])\n",
    "\n",
    "# Drop rows with missing (NA) values in the 'text_id' column, and reset the DataFrame's index.\n",
    "ml = ml.dropna(subset=[\"text_id\"]).reset_index().drop(columns='index')\n",
    "\n",
    "# Create two separate DataFrames for training and testing data based on the 'Train/Test' column.\n",
    "train = ml[ml['Train/Test'] == 'Train']\n",
    "test = ml[ml['Train/Test'] == 'Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f26410",
   "metadata": {},
   "source": [
    "## Training the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2c961d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell loops through all of the rows in our \"ml\" dataframe and creates the Completion pairs we would like to use for the\n",
    "data-preparation tool and fine-tune separated by training and test data, for comparison.\n",
    "\n",
    "Completion pairs is how you train the data to get the accurate output.\n",
    "\"\"\"\n",
    "\n",
    "# Training Data\n",
    "\n",
    "train_completionPairs = []\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    train_completionPairs += [\n",
    "        [\n",
    "            train.get('text_id').iloc[i],\n",
    "            \"Grantor: \" + train.get('Grantor').iloc[i] + \"\\nGrantee: \" + train.get('Grantee').iloc[i] +\n",
    "            \"\\nProgram: \" + train.get('Program').iloc[i] + \"\\nStart: \" + train.get('Date').iloc[i] +\n",
    "            \"\\nStop: \" + train.get('EndDate').iloc[i] + \"\\nAmount: \" + str(train.get('Amount').iloc[i]) +\n",
    "            \"\\nFunding Source: \" + str(train.get('Funding Source').iloc[i])\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "# Testing Data - just for comparison\n",
    "\n",
    "test_completionPairs = []\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    test_completionPairs += [\n",
    "        [\n",
    "            test.get('text_id').iloc[i],\n",
    "            \"Grantor: \" + test.get('Grantor').iloc[i] + \"\\nGrantee: \" + test.get('Grantee').iloc[i] +\n",
    "            \"\\nProgram: \" + train.get('Program').iloc[i] + \"\\nStart: \" + test.get('Date').iloc[i] +\n",
    "            \"\\nStop: \" + test.get('EndDate').iloc[i] + \"\\nAmount: \" + str(test.get('Amount').iloc[i]) +\n",
    "            \"\\nFunding Source: \" + str(test.get('Funding Source').iloc[i])\n",
    "        ]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb6e972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_completionPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94c91460",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_completionPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac38a31f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 41-42: truncated \\UXXXXXXXX escape (4076537351.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[61], line 29\u001b[1;36m\u001b[0m\n\u001b[1;33m    file.write(filedata)\"\"\"\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 41-42: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell starts by saving the directory where all of the original training files should be located. The directory\n",
    "should be edited accordingly. The script subsequently loops through all of these training documents, strips the text-files\n",
    "of new-line & unrecognizable characters, tokenizes the text-files, and takes the first 1500 text files and adds the \\n\\n###\\n\\n\n",
    "character (essential to get the fine-tune to work.) Afterwards, the cell adds each \"prompt\" and text-id into a double nested\n",
    "list which will be used to create a DataFrame in future cells. This cell also overwrites the original text-files, so it makes it\n",
    "so each individual text file can be used in the OpenAI preparation tool/used to test.\n",
    "\"\"\"\n",
    "\n",
    "# Create an empty list 'train_prompts' to store prompts and text-ids.\n",
    "train_prompts = []\n",
    "\n",
    "# Define the directory where the original training files are located. Update this directory accordingly.\n",
    "directory = \"test_txt\"\n",
    "\n",
    "# Loop through each file in the specified directory.\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "\n",
    "    # Read the content of the file, remove new-line characters and unrecognizable characters, and tokenize the text.\n",
    "    with open(file_path, 'r', encoding=\"latin-1\") as file:\n",
    "        filedata = file.readlines()\n",
    "        filedata = ' '.join([s.rstrip('\\n') for s in filedata])\n",
    "        filedata = remove_non_ascii(filedata)\n",
    "\n",
    "        nltk_tokens = nltk.word_tokenize(filedata)\n",
    "\n",
    "        # Take the first 1500 tokens, add '###' as a separator, and create the 'prompt' for fine-tuning.\n",
    "        filedata = ' '.join(nltk_tokens[:1500]) + \"\\n\\n###\\n\\n\"\n",
    "\n",
    "    # Add the 'prompt' and filename ('text-id') to the 'train_prompts' list.\n",
    "    train_prompts += [[filename, filedata]]\n",
    "\n",
    "    # Overwrite the original text file with the modified content.\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2d44e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is for the folder containing all the training and testing data documents and creates the prompts for them.\n",
    "'''\n",
    "\n",
    "# Create an empty list 'prompts' to store prompts and text-ids.\n",
    "prompts = []\n",
    "\n",
    "# Define the directory where all the training and testing data documents are located. Update this directory accordingly.\n",
    "directory = \"all_text_docs\"\n",
    "\n",
    "# Loop through each file in the specified directory.\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    \n",
    "    # Check if it is a file with a '.txt' extension.\n",
    "    if filename.endswith('.txt'):\n",
    "        # Read the content of the file, remove new-line characters and unrecognizable characters, and tokenize the text.\n",
    "        with open(f, 'r', encoding=\"latin-1\") as file:\n",
    "            filedata = file.readlines()\n",
    "            filedata = ' '.join([s.rstrip('\\n') for s in filedata])\n",
    "            filedata = remove_non_ascii(filedata)\n",
    "\n",
    "            nltk_tokens = nltk.word_tokenize(filedata)\n",
    "\n",
    "            # Take the first 1500 tokens, add '###' as a separator, and create the 'prompt'.\n",
    "            # THIS CROPS OUT THE CONTRACT TEXT WE NEED FOR MOST FILES, FIX THIS\n",
    "            filedata = ' '.join(nltk_tokens[:1500]) + \"\\n\\n###\\n\\n\"\n",
    "        \n",
    "        # Add the 'prompt' and filename ('text-id') to the 'prompts' list.\n",
    "        prompts += [[filename, filedata]]\n",
    "\n",
    "        # Overwrite the original text file with the modified content.\n",
    "        with open(f, 'w') as file:\n",
    "            file.write(filedata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "19d3082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell creates a DataFrame of the prompts and completions, and the cell under merges the files under their text_ids, \n",
    "drops the text_ids, and saves as a CSV. The directory should be edited accordingly dependent on which device you are using \n",
    "this on. I originally named my \"prompt-completion pairs\" finetuneTrain0608.csv\n",
    "\"\"\"\n",
    "\n",
    "# Create a DataFrame 'train_prompt_df' from the 'train_prompts' list with columns \"text_id\" and \"prompt\".\n",
    "train_prompt_df = pd.DataFrame(train_prompts, columns=[\"text_id\", \"prompt\"])\n",
    "\n",
    "# Create a DataFrame 'train_completion_df' from the 'train_completionPairs' list with columns \"text_id\" and \"completion\".\n",
    "train_completion_df = pd.DataFrame(train_completionPairs, columns=[\"text_id\", \"completion\"])\n",
    "train_completion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b173fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is used to create the jsonl file to train the data for the AI engine using the prompt-completion pairs created above.\n",
    "Directions on how to turn a CSV into a JSONL file and creating an AI engine via the terminal are linked below.\n",
    "\n",
    "https://platform.openai.com/docs/guides/fine-tuning\n",
    "'''\n",
    "\n",
    "# Merge 'train_prompt_df' and 'train_completion_df' DataFrames based on the 'text_id' column.\n",
    "# Drop the 'text_id' column and set the 'prompt' column as the index.\n",
    "merged_df = train_prompt_df.merge(train_completion_df, left_on=\"text_id\", right_on=\"text_id\").drop(columns=\"text_id\").set_index(\"prompt\")\n",
    "\n",
    "# Save the merged DataFrame as a CSV file\n",
    "merged_df.to_csv(r\"dir_finetuneTrain0608.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "58f4315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is to clean up the input from the txt document to a readable prompt for testing files by cleaning white spaces, random characters, \n",
    "and ensuring the necessary \"\\n\\n###\\n\\n\" is added at the end,\n",
    "\n",
    "'''\n",
    "def condense_file(file_path):\n",
    "    # Read the contents of the file and clean it by replacing newlines with spaces, removing carriage returns,\n",
    "    # and ensuring that any existing '###' is removed.\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read().replace(\"\\n\", \" \").replace(\"\\r\", \"\").replace('###', \"\")\n",
    "\n",
    "    # Add the necessary \"\\n\\n###\\n\\n\" at the end and strip any leading/trailing whitespace.\n",
    "    return content.strip() + \"\\n\\n###\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e42147",
   "metadata": {},
   "source": [
    "# <b>TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4c17f",
   "metadata": {},
   "source": [
    "## <font color='red'>IMPORTANT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d19e4",
   "metadata": {},
   "source": [
    "#### Be sure to test on individual files to understand how the finetuning is operating. Also, creating a response charges the OpenAI account so test on individual documents before trying on a whole dataset.\n",
    "#### As of right now, we know there is a major issue with what part of the file we are feeding into the *create_response()* function. \n",
    "#### Try to find a trend in words and phrases that are preceding the information we're looking for (Grantor, Grantee, ...) to know what part of the files should be cut into. \n",
    "##### You could also look to see if there's a consistency of how far into the contract the information is, but this is far less likely considering some contracts are 67 pages long and others are 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3d66ec68",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'confidence'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m cf \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_directory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_text_docs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity of Lemon Grove Home Start.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m testFile \u001b[38;5;241m=\u001b[39m condense_file(cf)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mcreate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestFile\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[140], line 20\u001b[0m, in \u001b[0;36mcreate_response\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_response\u001b[39m(prompt):\n\u001b[0;32m     14\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     15\u001b[0m         engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurie:ft-personal-2023-07-14-02-12-12\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m prompt,\n\u001b[0;32m     17\u001b[0m         temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m, \n\u001b[0;32m     18\u001b[0m         max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     19\u001b[0m         stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEND\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     confidence \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfidence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], confidence\n",
      "\u001b[1;31mKeyError\u001b[0m: 'confidence'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Edit the directory. Mine is connected to the GitHub repo and my jupyterhub to automatically update them.\n",
    "This cell was just being used to test individual files - it might be good to know that there is a max usage on each API key based on tokens inputted, \n",
    "so I've been testing indiivdual files to note differences in outputs.\n",
    "'''\n",
    "current_directory = os.getcwd()\n",
    "cf = os.path.join(current_directory, 'all_text_docs', 'City of Lemon Grove Home Start.txt')\n",
    "\n",
    "testFile = condense_file(cf)\n",
    "\n",
    "# Creating a response charges the OpenAI account so test on individual documents before trying on a whole dataset\n",
    "# create_response(testFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc7a7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is used to test the data. This is using the functions created earlier in the code to clean the txt file prompts, \n",
    "check token limit and outputs a print line for the files that are over the limit before attempting to test them. It then tests \n",
    "the files that are within the token limit. This just tests one file at a time given the filepath.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "##Script to test our \"testing\" data.  Enter new text into testFile variable and completion example is found under \"text\"\n",
    "\n",
    "def test_files(file_path):\n",
    "    # Read and condense the file contents\n",
    "    condensed_file = condense_file(file_path)\n",
    "\n",
    "    # Count the number of tokens in the condensed file\n",
    "    token_count = count_tokens(condensed_file)\n",
    "\n",
    "    # Check if the token count exceeds the limit\n",
    "    if token_count > 2048:\n",
    "        return \"Error: The file {file_path} contains more than 2048 tokens.\"\n",
    "\n",
    "    # Create a response using the condensed file\n",
    "    response = create_response(condensed_file)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "438de42e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file CRC - CDBG FY 2021-22 (Executed) (1).txt: This model's maximum context length is 2049 tokens, however you requested 9668 tokens (9568 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file CRC 2020-21 Facility Improvement (2.22.2021) (1).txt: This model's maximum context length is 2049 tokens, however you requested 9607 tokens (9507 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file CRC Homeless Prevention - FY19-20 Executed Agreement (1).txt: This model's maximum context length is 2049 tokens, however you requested 12017 tokens (11917 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file CRC MOU Motel Voucher (1).txt: This model's maximum context length is 2049 tokens, however you requested 10523 tokens (10423 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file CRC MOU Motel Voucher.txt: This model's maximum context length is 2049 tokens, however you requested 10523 tokens (10423 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file East County Transitional Living Center     Emergency Shelter Program for Homeless.txt: This model's maximum context length is 2049 tokens, however you requested 2444 tokens (2344 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file Elderhelp of San Diego - 3rd Amendment.txt: This model's maximum context length is 2049 tokens, however you requested 6742 tokens (6642 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file Executed Agreement CDBG CATHOLIC CHARITIES.txt: This model's maximum context length is 2049 tokens, however you requested 11904 tokens (11804 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file Executed_First Amendment_ JFS Safe Parking Contract.txt: This model's maximum context length is 2049 tokens, however you requested 10260 tokens (10160 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file HHI-21-04 Agreement - Storage Connect Center II (MHS) (1).txt: This model's maximum context length is 2049 tokens, however you requested 5212 tokens (5112 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file HHI-21-13 Agreement - Day Center (FJV) (1).txt: This model's maximum context length is 2049 tokens, however you requested 5816 tokens (5716 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file Home Start Inc.txt: This model's maximum context length is 2049 tokens, however you requested 10387 tokens (10287 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file Interfaith Community Services - Second Amendment.txt: This model's maximum context length is 2049 tokens, however you requested 7203 tokens (7103 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file Interfaith_Community_Services_Inc__2020-03-23_.txt: This model's maximum context length is 2049 tokens, however you requested 2396 tokens (2296 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file Jewish Family Service of San Diego - First Amendment.txt: This model's maximum context length is 2049 tokens, however you requested 8726 tokens (8626 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file McAlister Agreement - Executed (10.22.2021) (1).txt: This model's maximum context length is 2049 tokens, however you requested 12038 tokens (11938 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file Mental Health Systems Transitional Storage Agreement-executed.txt: This model's maximum context length is 2049 tokens, however you requested 10599 tokens (10499 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file Opening Doors MOU 21-22.txt: This model's maximum context length is 2049 tokens, however you requested 11685 tokens (11585 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file PRA 4058 - 5466_211 SD.txt: This model's maximum context length is 2049 tokens, however you requested 10427 tokens (10327 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file PRA 4058 - 6446_NC Lifeline.txt: This model's maximum context length is 2049 tokens, however you requested 7400 tokens (7300 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file PRA 4058 - 6455_Interfaith.txt: This model's maximum context length is 2049 tokens, however you requested 7209 tokens (7109 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing file PRA 4058 - Contract 6482 MOU w. ARS.txt: This model's maximum context length is 2049 tokens, however you requested 6314 tokens (6214 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell is using an automated process to loop through all the downloaded text documents and creates a nested list to be turned into a csv file, \n",
    "a list that contains the names of the files that were too large to test, and prints out any errors with reading the inputted files. \n",
    "The data is expanded in the cells below.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "csvRows = []\n",
    "largeFiles = [] # list of txt doc names that had too large of a token size to test\n",
    "skipped = [] # list of other files skipped\n",
    "\n",
    "# Get the current working directory (JupyterHub project directory)\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the folder name within the current directory\n",
    "folder_path = os.path.join(current_directory, 'all_text_docs')\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Get the full path of the file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    try:\n",
    "        # Perform fine-tuning on the file here\n",
    "        string_munip = test_files(file_path)\n",
    "        csvRows.append(string_munip)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping file {file_name}: {str(e)}\")\n",
    "        skipped.append(file_name)\n",
    "        continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_name}: {str(e)}\")\n",
    "        largeFiles.append(file_name)\n",
    "        continue\n",
    "\n",
    "#for row in csvRows:\n",
    "    #print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0051aaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRC - CDBG FY 2021-22 (Executed) (1).txt',\n",
       " 'CRC 2020-21 Facility Improvement (2.22.2021) (1).txt',\n",
       " 'CRC Homeless Prevention - FY19-20 Executed Agreement (1).txt',\n",
       " 'CRC MOU Motel Voucher (1).txt',\n",
       " 'CRC MOU Motel Voucher.txt',\n",
       " 'East County Transitional Living Center     Emergency Shelter Program for Homeless.txt',\n",
       " 'Elderhelp of San Diego - 3rd Amendment.txt',\n",
       " 'Executed Agreement CDBG CATHOLIC CHARITIES.txt',\n",
       " 'Executed_First Amendment_ JFS Safe Parking Contract.txt',\n",
       " 'HHI-21-04 Agreement - Storage Connect Center II (MHS) (1).txt',\n",
       " 'HHI-21-13 Agreement - Day Center (FJV) (1).txt',\n",
       " 'Home Start Inc.txt',\n",
       " 'Interfaith Community Services - Second Amendment.txt',\n",
       " 'Interfaith_Community_Services_Inc__2020-03-23_.txt',\n",
       " 'Jewish Family Service of San Diego - First Amendment.txt',\n",
       " 'McAlister Agreement - Executed (10.22.2021) (1).txt',\n",
       " 'Mental Health Systems Transitional Storage Agreement-executed.txt',\n",
       " 'Opening Doors MOU 21-22.txt',\n",
       " 'PRA 4058 - 5466_211 SD.txt',\n",
       " 'PRA 4058 - 6446_NC Lifeline.txt',\n",
       " 'PRA 4058 - 6455_Interfaith.txt',\n",
       " 'PRA 4058 - Contract 6482 MOU w. ARS.txt']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largeFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98209106",
   "metadata": {},
   "source": [
    "## might need to check for white space issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "63d80491",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in csvRows:\n",
    "    string_munip = row.strip()\n",
    "    cleanedValues = string_munip.replace(\"Grantor: \",\"\").replace(\"Grantee: \",\"\").replace(\"Program: \",\"\").replace(\"Start: \",\"\").replace(\"Stop: \",\"\").replace(\"Amount: \",\"\").replace(\"Funding Source: \",\"\")\n",
    "    removedNewLines = cleanedValues.replace(\"\\n\", \",\")\n",
    "    data.append(removedNewLines.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "977a3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = ['Grantor', 'Grantee', 'Program', 'Start', 'Stop', 'Amount', 'Funding Source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fc2331b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.csv'\n",
    "\n",
    "# Check if the file exists\n",
    "file_exists = False\n",
    "try:\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        if any(row for row in reader):\n",
    "            file_exists = True\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# Open the file in 'a' mode (append mode) with newline=''\n",
    "with open(filename, 'a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write column names if the file is empty\n",
    "    if not file_exists:\n",
    "        column_names = ['Grantor', 'Grantee', 'Program', 'Start', 'Stop', 'Amount', 'Funding Source']\n",
    "        writer.writerow(column_names)\n",
    "\n",
    "    # Write the data as rows\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "45b8f556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grantor</th>\n",
       "      <th>Grantee</th>\n",
       "      <th>Program</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Funding Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of San Marcos</td>\n",
       "      <td>Alliance for Regional Solutions</td>\n",
       "      <td>Winter Shelters</td>\n",
       "      <td>06/13/17</td>\n",
       "      <td>06/30/20</td>\n",
       "      <td>66300</td>\n",
       "      <td>City Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of San Marcos</td>\n",
       "      <td>Alliance for Regional Solutions</td>\n",
       "      <td>Shelter Services</td>\n",
       "      <td>07/01/18</td>\n",
       "      <td>06/30/23</td>\n",
       "      <td>30000</td>\n",
       "      <td>City Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>City of Chula Vista</td>\n",
       "      <td>Alpha Project</td>\n",
       "      <td>CV - Transitional Employment Services</td>\n",
       "      <td>12/07/21</td>\n",
       "      <td>12/09/22</td>\n",
       "      <td>40000</td>\n",
       "      <td>ARPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>City of Chula Vista</td>\n",
       "      <td>Alpha Project</td>\n",
       "      <td>Take Back the Streets</td>\n",
       "      <td>06/01/21</td>\n",
       "      <td>06/30/22</td>\n",
       "      <td>30000</td>\n",
       "      <td>CDBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>City of Vista</td>\n",
       "      <td>Alpha Project</td>\n",
       "      <td>Homelessness Outreach Services</td>\n",
       "      <td>07/01/20</td>\n",
       "      <td>06/30/21</td>\n",
       "      <td>400000</td>\n",
       "      <td>CDBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>City of Coronado</td>\n",
       "      <td>St. Vincent de Paul Village</td>\n",
       "      <td>Shelter Services</td>\n",
       "      <td>05/01/21</td>\n",
       "      <td>05/01/24</td>\n",
       "      <td>287401</td>\n",
       "      <td>Affordable Housing Fund account 266490-8030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>City of El Cajon</td>\n",
       "      <td>Salvation Army</td>\n",
       "      <td>A Way Back Home</td>\n",
       "      <td>10/6/20</td>\n",
       "      <td>10/05/21</td>\n",
       "      <td>10700</td>\n",
       "      <td>City Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>City of Carlsbad</td>\n",
       "      <td>Urban Corps of San Diego County</td>\n",
       "      <td>Neighborhood Revitalization Services</td>\n",
       "      <td>06/19/20</td>\n",
       "      <td>06/19/22</td>\n",
       "      <td>35000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>City of Carlsbad</td>\n",
       "      <td>Women 's Resource Center</td>\n",
       "      <td>Outreach Services</td>\n",
       "      <td>07/01/17</td>\n",
       "      <td>06/30/18</td>\n",
       "      <td>148996</td>\n",
       "      <td>CDBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>City of Carlsbad</td>\n",
       "      <td>Women 's Resource Center</td>\n",
       "      <td>Grantee Services</td>\n",
       "      <td>07/01/18</td>\n",
       "      <td>06/30/20</td>\n",
       "      <td>1200</td>\n",
       "      <td>CDBG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Grantor                           Grantee  \\\n",
       "0    City of San Marcos   Alliance for Regional Solutions   \n",
       "1    City of San Marcos  Alliance for Regional Solutions    \n",
       "2   City of Chula Vista                     Alpha Project   \n",
       "3   City of Chula Vista                    Alpha Project    \n",
       "4         City of Vista                     Alpha Project   \n",
       "..                  ...                               ...   \n",
       "90     City of Coronado       St. Vincent de Paul Village   \n",
       "91     City of El Cajon                    Salvation Army   \n",
       "92     City of Carlsbad   Urban Corps of San Diego County   \n",
       "93     City of Carlsbad          Women 's Resource Center   \n",
       "94     City of Carlsbad          Women 's Resource Center   \n",
       "\n",
       "                                  Program     Start      Stop  Amount  \\\n",
       "0                         Winter Shelters  06/13/17  06/30/20   66300   \n",
       "1                        Shelter Services  07/01/18  06/30/23   30000   \n",
       "2   CV - Transitional Employment Services  12/07/21  12/09/22   40000   \n",
       "3                   Take Back the Streets  06/01/21  06/30/22   30000   \n",
       "4          Homelessness Outreach Services  07/01/20  06/30/21  400000   \n",
       "..                                    ...       ...       ...     ...   \n",
       "90                       Shelter Services  05/01/21  05/01/24  287401   \n",
       "91                       A Way Back Home    10/6/20  10/05/21   10700   \n",
       "92   Neighborhood Revitalization Services  06/19/20  06/19/22   35000   \n",
       "93                      Outreach Services  07/01/17  06/30/18  148996   \n",
       "94                       Grantee Services  07/01/18  06/30/20    1200   \n",
       "\n",
       "                                 Funding Source  \n",
       "0                                   City Budget  \n",
       "1                                   City Budget  \n",
       "2                                          ARPA  \n",
       "3                                          CDBG  \n",
       "4                                          CDBG  \n",
       "..                                          ...  \n",
       "90  Affordable Housing Fund account 266490-8030  \n",
       "91                                  City Budget  \n",
       "92                                          NaN  \n",
       "93                                         CDBG  \n",
       "94                                         CDBG  \n",
       "\n",
       "[95 rows x 7 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvfile = pd.read_csv('data.csv')\n",
    "csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8f78a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(text):\n",
    "    return re.sub(r'[{}\\'‘’]'.format(string.punctuation), '', text).upper().strip()\n",
    "to_std = ['Grantor', 'Grantee', 'Program', 'Funding Source','Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9b5ed7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grantor</th>\n",
       "      <th>Grantee</th>\n",
       "      <th>Program</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Funding Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CITY OF SAN MARCOS</td>\n",
       "      <td>ALLIANCE FOR REGIONAL SOLUTIONS</td>\n",
       "      <td>WINTER SHELTERS</td>\n",
       "      <td>06/13/17</td>\n",
       "      <td>06/30/20</td>\n",
       "      <td>66300</td>\n",
       "      <td>CITY BUDGET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CITY OF SAN MARCOS</td>\n",
       "      <td>ALLIANCE FOR REGIONAL SOLUTIONS</td>\n",
       "      <td>SHELTER SERVICES</td>\n",
       "      <td>07/01/18</td>\n",
       "      <td>06/30/23</td>\n",
       "      <td>30000</td>\n",
       "      <td>CITY BUDGET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CITY OF CHULA VISTA</td>\n",
       "      <td>ALPHA PROJECT</td>\n",
       "      <td>CV  TRANSITIONAL EMPLOYMENT SERVICES</td>\n",
       "      <td>12/07/21</td>\n",
       "      <td>12/09/22</td>\n",
       "      <td>40000</td>\n",
       "      <td>ARPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CITY OF CHULA VISTA</td>\n",
       "      <td>ALPHA PROJECT</td>\n",
       "      <td>TAKE BACK THE STREETS</td>\n",
       "      <td>06/01/21</td>\n",
       "      <td>06/30/22</td>\n",
       "      <td>30000</td>\n",
       "      <td>CDBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CITY OF VISTA</td>\n",
       "      <td>ALPHA PROJECT</td>\n",
       "      <td>HOMELESSNESS OUTREACH SERVICES</td>\n",
       "      <td>07/01/20</td>\n",
       "      <td>06/30/21</td>\n",
       "      <td>400000</td>\n",
       "      <td>CDBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>CITY OF CORONADO</td>\n",
       "      <td>ST VINCENT DE PAUL VILLAGE</td>\n",
       "      <td>SHELTER SERVICES</td>\n",
       "      <td>05/01/21</td>\n",
       "      <td>05/01/24</td>\n",
       "      <td>287401</td>\n",
       "      <td>AFFORDABLE HOUSING FUND ACCOUNT 2664908030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>CITY OF EL CAJON</td>\n",
       "      <td>SALVATION ARMY</td>\n",
       "      <td>A WAY BACK HOME</td>\n",
       "      <td>10/6/20</td>\n",
       "      <td>10/05/21</td>\n",
       "      <td>10700</td>\n",
       "      <td>CITY BUDGET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>CITY OF CARLSBAD</td>\n",
       "      <td>URBAN CORPS OF SAN DIEGO COUNTY</td>\n",
       "      <td>NEIGHBORHOOD REVITALIZATION SERVICES</td>\n",
       "      <td>06/19/20</td>\n",
       "      <td>06/19/22</td>\n",
       "      <td>35000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>CITY OF CARLSBAD</td>\n",
       "      <td>WOMEN S RESOURCE CENTER</td>\n",
       "      <td>OUTREACH SERVICES</td>\n",
       "      <td>07/01/17</td>\n",
       "      <td>06/30/18</td>\n",
       "      <td>148996</td>\n",
       "      <td>CDBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>CITY OF CARLSBAD</td>\n",
       "      <td>WOMEN S RESOURCE CENTER</td>\n",
       "      <td>GRANTEE SERVICES</td>\n",
       "      <td>07/01/18</td>\n",
       "      <td>06/30/20</td>\n",
       "      <td>1200</td>\n",
       "      <td>CDBG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Grantor                          Grantee  \\\n",
       "0    CITY OF SAN MARCOS  ALLIANCE FOR REGIONAL SOLUTIONS   \n",
       "1    CITY OF SAN MARCOS  ALLIANCE FOR REGIONAL SOLUTIONS   \n",
       "2   CITY OF CHULA VISTA                    ALPHA PROJECT   \n",
       "3   CITY OF CHULA VISTA                    ALPHA PROJECT   \n",
       "4         CITY OF VISTA                    ALPHA PROJECT   \n",
       "..                  ...                              ...   \n",
       "90     CITY OF CORONADO       ST VINCENT DE PAUL VILLAGE   \n",
       "91     CITY OF EL CAJON                   SALVATION ARMY   \n",
       "92     CITY OF CARLSBAD  URBAN CORPS OF SAN DIEGO COUNTY   \n",
       "93     CITY OF CARLSBAD          WOMEN S RESOURCE CENTER   \n",
       "94     CITY OF CARLSBAD          WOMEN S RESOURCE CENTER   \n",
       "\n",
       "                                 Program     Start      Stop  Amount  \\\n",
       "0                        WINTER SHELTERS  06/13/17  06/30/20   66300   \n",
       "1                       SHELTER SERVICES  07/01/18  06/30/23   30000   \n",
       "2   CV  TRANSITIONAL EMPLOYMENT SERVICES  12/07/21  12/09/22   40000   \n",
       "3                  TAKE BACK THE STREETS  06/01/21  06/30/22   30000   \n",
       "4         HOMELESSNESS OUTREACH SERVICES  07/01/20  06/30/21  400000   \n",
       "..                                   ...       ...       ...     ...   \n",
       "90                      SHELTER SERVICES  05/01/21  05/01/24  287401   \n",
       "91                       A WAY BACK HOME   10/6/20  10/05/21   10700   \n",
       "92  NEIGHBORHOOD REVITALIZATION SERVICES  06/19/20  06/19/22   35000   \n",
       "93                     OUTREACH SERVICES  07/01/17  06/30/18  148996   \n",
       "94                      GRANTEE SERVICES  07/01/18  06/30/20    1200   \n",
       "\n",
       "                                Funding Source  \n",
       "0                                  CITY BUDGET  \n",
       "1                                  CITY BUDGET  \n",
       "2                                         ARPA  \n",
       "3                                         CDBG  \n",
       "4                                         CDBG  \n",
       "..                                         ...  \n",
       "90  AFFORDABLE HOUSING FUND ACCOUNT 2664908030  \n",
       "91                                 CITY BUDGET  \n",
       "92                                         NaN  \n",
       "93                                        CDBG  \n",
       "94                                        CDBG  \n",
       "\n",
       "[95 rows x 7 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvfile[to_std] = csvfile[to_std].applymap(lambda x: standardize_text(x) if isinstance(x, str) else x)\n",
    "csvfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4c1dd",
   "metadata": {},
   "source": [
    "# Data Cleaning / Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0d210871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train/Test</th>\n",
       "      <th>Grantor</th>\n",
       "      <th>Grantee</th>\n",
       "      <th>Program</th>\n",
       "      <th>Date</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Funding Source</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>CITY OF CHULA VISTA</td>\n",
       "      <td>ALPHA PROJECT</td>\n",
       "      <td>TAKE BACK THE STREETS</td>\n",
       "      <td>06/01/21</td>\n",
       "      <td>06/30/22</td>\n",
       "      <td>45000</td>\n",
       "      <td>CDBG</td>\n",
       "      <td>Alpha Project _Take Back the Streets_text.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train</td>\n",
       "      <td>CITY OF CHULA VISTA</td>\n",
       "      <td>JACOBS AND CUSHMAN SAN DIEGO FOOD BANK</td>\n",
       "      <td>CV  FOOD SERVICES</td>\n",
       "      <td>11/16/21</td>\n",
       "      <td>11/16/22</td>\n",
       "      <td>100000</td>\n",
       "      <td>ARPA</td>\n",
       "      <td>Jacobs and Cushman San Diego Food Bank_CV - Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train</td>\n",
       "      <td>CITY OF CHULA VISTA</td>\n",
       "      <td>ALPHA PROJECT</td>\n",
       "      <td>CV  TRANSITIONAL EMPLOYMENT SERVICES</td>\n",
       "      <td>12/07/21</td>\n",
       "      <td>12/16/22</td>\n",
       "      <td>100000</td>\n",
       "      <td>ARPA</td>\n",
       "      <td>Alpha Project _CV - Transitional Employment Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train</td>\n",
       "      <td>CITY OF CHULA VISTA</td>\n",
       "      <td>SBCS</td>\n",
       "      <td>CV  EMERGENCY DOMESTIC VIOLENCE SERVICES</td>\n",
       "      <td>04/26/22</td>\n",
       "      <td>04/26/23</td>\n",
       "      <td>200000</td>\n",
       "      <td>ARPA</td>\n",
       "      <td>SBCS_CV - Emergency Domestic Violence Services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train</td>\n",
       "      <td>CITY OF CHULA VISTA</td>\n",
       "      <td>FAMILY HEALTH CENTERS OF SAN DIEGO</td>\n",
       "      <td>20212022 MOBILE MEDICAL UNIT</td>\n",
       "      <td>06/01/21</td>\n",
       "      <td>06/30/22</td>\n",
       "      <td>30000</td>\n",
       "      <td>CDBG</td>\n",
       "      <td>Family Health Centers of San Diego_2021-2022 M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Test</td>\n",
       "      <td>SDHC</td>\n",
       "      <td>FATHER JOES VILLAGE</td>\n",
       "      <td>CASE MANAGEMENT SERVICES</td>\n",
       "      <td>7/1/2020</td>\n",
       "      <td>5/31/21</td>\n",
       "      <td>11945463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HHI-21-21 Agreement - Case Management (FJV).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Test</td>\n",
       "      <td>SDHC</td>\n",
       "      <td>SAN DIEGO YOUTH SERVICES</td>\n",
       "      <td>SAFETAY NETWORK PROGRAM</td>\n",
       "      <td>1/15/21</td>\n",
       "      <td>6/30/21</td>\n",
       "      <td>10025166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HHI-21-31 Agreement (SafeTAY Network Program -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Test</td>\n",
       "      <td>SDHC</td>\n",
       "      <td>SAN DIEGO YOUTH SERVICES</td>\n",
       "      <td>YOUTH EMERGENCY SHELTER</td>\n",
       "      <td>1/15/21</td>\n",
       "      <td>6/30/21</td>\n",
       "      <td>7248922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HHI-21-32 Agreement (Youth Emergency Shelter -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Test</td>\n",
       "      <td>SDHC</td>\n",
       "      <td>SAN DIEGO LGBT COMMUNITY CENTER</td>\n",
       "      <td>SAFETAY NETWORK PROGRAM</td>\n",
       "      <td>1/15/21</td>\n",
       "      <td>6/30/21</td>\n",
       "      <td>6501977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HHI-21-33 Agreement (SafeTAY Network Program -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Test</td>\n",
       "      <td>SDHC</td>\n",
       "      <td>URBAN STREET ANGLES</td>\n",
       "      <td>SAFETAY NETWORK PROGRAM</td>\n",
       "      <td>1/15/21</td>\n",
       "      <td>6/30/21</td>\n",
       "      <td>7662393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HHI-21-34 Agreement (SafeTAY Network Program -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train/Test              Grantor                                 Grantee  \\\n",
       "0       Train  CITY OF CHULA VISTA                           ALPHA PROJECT   \n",
       "1       Train  CITY OF CHULA VISTA  JACOBS AND CUSHMAN SAN DIEGO FOOD BANK   \n",
       "2       Train  CITY OF CHULA VISTA                           ALPHA PROJECT   \n",
       "3       Train  CITY OF CHULA VISTA                                    SBCS   \n",
       "4       Train  CITY OF CHULA VISTA      FAMILY HEALTH CENTERS OF SAN DIEGO   \n",
       "..        ...                  ...                                     ...   \n",
       "82       Test                 SDHC                     FATHER JOES VILLAGE   \n",
       "83       Test                 SDHC                SAN DIEGO YOUTH SERVICES   \n",
       "84       Test                 SDHC                SAN DIEGO YOUTH SERVICES   \n",
       "85       Test                 SDHC         SAN DIEGO LGBT COMMUNITY CENTER   \n",
       "86       Test                 SDHC                     URBAN STREET ANGLES   \n",
       "\n",
       "                                     Program      Date   EndDate    Amount  \\\n",
       "0                      TAKE BACK THE STREETS  06/01/21  06/30/22     45000   \n",
       "1                          CV  FOOD SERVICES  11/16/21  11/16/22    100000   \n",
       "2       CV  TRANSITIONAL EMPLOYMENT SERVICES  12/07/21  12/16/22    100000   \n",
       "3   CV  EMERGENCY DOMESTIC VIOLENCE SERVICES  04/26/22  04/26/23    200000   \n",
       "4               20212022 MOBILE MEDICAL UNIT  06/01/21  06/30/22     30000   \n",
       "..                                       ...       ...       ...       ...   \n",
       "82                  CASE MANAGEMENT SERVICES  7/1/2020   5/31/21  11945463   \n",
       "83                   SAFETAY NETWORK PROGRAM   1/15/21   6/30/21  10025166   \n",
       "84                   YOUTH EMERGENCY SHELTER   1/15/21   6/30/21   7248922   \n",
       "85                   SAFETAY NETWORK PROGRAM   1/15/21   6/30/21   6501977   \n",
       "86                   SAFETAY NETWORK PROGRAM   1/15/21   6/30/21   7662393   \n",
       "\n",
       "   Funding Source                                            text_id  \n",
       "0            CDBG      Alpha Project _Take Back the Streets_text.txt  \n",
       "1            ARPA  Jacobs and Cushman San Diego Food Bank_CV - Fo...  \n",
       "2            ARPA  Alpha Project _CV - Transitional Employment Se...  \n",
       "3            ARPA  SBCS_CV - Emergency Domestic Violence Services...  \n",
       "4            CDBG  Family Health Centers of San Diego_2021-2022 M...  \n",
       "..            ...                                                ...  \n",
       "82            NaN    HHI-21-21 Agreement - Case Management (FJV).pdf  \n",
       "83            NaN  HHI-21-31 Agreement (SafeTAY Network Program -...  \n",
       "84            NaN  HHI-21-32 Agreement (Youth Emergency Shelter -...  \n",
       "85            NaN  HHI-21-33 Agreement (SafeTAY Network Program -...  \n",
       "86            NaN  HHI-21-34 Agreement (SafeTAY Network Program -...  \n",
       "\n",
       "[72 rows x 9 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Filters out data that isn't used in training/testing data and files that were skipped or too large.\n",
    "'''\n",
    "new_ml = ml[~ml.get('text_id').isin(largeFiles)]#+skipped)]\n",
    "new_ml = new_ml[new_ml.get('Train/Test').isin(['Train','Test'])]\n",
    "new_ml[to_std] = new_ml[to_std].applymap(lambda x: standardize_text(x) if isinstance(x, str) else x)\n",
    "new_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b84f6dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '20 Alliance for Regional Solutions Shelter Services.txt',\n",
       " 'Alpha Project _CV - Transitional Employment Services_text.txt',\n",
       " 'Alpha Project _Take Back the Streets_text.txt',\n",
       " 'Alpha Project.txt',\n",
       " 'CDBG Emergency Shelter Subrecipient Agreement Executed Contract FY 19-20.txt',\n",
       " 'City of Lemon Grove Home Start.txt',\n",
       " 'Crisis House      Improve Fencing_OCR.txt',\n",
       " 'Crisis House     HVAC Replacements.txt',\n",
       " 'Crisis House    Homelessness Prevention Case Management Services.txt',\n",
       " 'Crisis House  CV - Rapid Rehousing Services.txt',\n",
       " 'Crisis House  General Homelessness Services.txt',\n",
       " 'Crisis House Prevention Programs (1).txt',\n",
       " 'Crisis House Prevention Programs (2).txt',\n",
       " 'Crisis House Prevention Programs.txt',\n",
       " 'Department of Housing and Community Development       General Funding for Homelessness Services.txt',\n",
       " 'desktop.ini',\n",
       " 'East County Chamber of Commerce Interprovider Networking and Program Facilitation.txt',\n",
       " 'East County Transitional Living Center     Emergency Shelter.txt',\n",
       " 'East County Transitional Living Center     Railing Replacement.txt',\n",
       " 'East County Transitional Living Center     Security Fencing.txt',\n",
       " 'Family Health Centers of San Diego_2021-2022 Mobile Medical Unit_text.txt',\n",
       " 'Fully_Executed_UC_PW_contract_FY19.txt',\n",
       " 'Home Start     CV - Housing Stability Services.txt',\n",
       " 'Home Start     CV - Outreach Support Services Program.txt',\n",
       " 'Home Start     Motel Voucher Program.txt',\n",
       " 'Home Start     Rental Assistance.txt',\n",
       " 'Home Start    Outreach Services.txt',\n",
       " 'Home Start Inc  CV - Rental Assistance (2).txt',\n",
       " 'Home Start Inc  CV - Rental Assistance.txt',\n",
       " 'ICS - Amendment #2 (Executed) 10.11.2021.txt',\n",
       " 'Interfaith Community Services     CV - Quarantined Entry into Emergency Shelter.txt',\n",
       " 'Interfaith Community Services     Rotational Shelter Program.txt',\n",
       " 'Interfaith Community Services July Outreach Services.txt',\n",
       " 'Interfaith Shelter Network of San Diego   CV - Rental Assistance.txt',\n",
       " 'Interfaith_Community_Services_Contract_FY2020-21.txt',\n",
       " 'Interfaith_Community_Services_Inc__2018-06-01_.txt',\n",
       " 'Interfaith_Community_Services__2019.txt',\n",
       " 'Jacobs & Cushman San Diego Food Bank 2021-2022 Food 4 Kids Backpack Program.txt',\n",
       " 'Jacobs and Cushman San Diego Food Bank_CV - Food Services_text.txt',\n",
       " 'Legal_Aid_Society_of_San_Diego__2018-11-05_.txt',\n",
       " 'McAlister Institute for Treatment & Education Case Management Services.txt',\n",
       " 'McAlister Institute for Treatment and Education Inc._Work For Hope_text.txt',\n",
       " 'Meals_on_Wheels_2019.txt',\n",
       " 'North County Lifeline RAP.txt',\n",
       " 'OH Executed Contract.txt',\n",
       " 'People Assisting the Homeless      CV - Outreach and General Homelessness Services.txt',\n",
       " 'Rocket_John_Contract.txt',\n",
       " 'San Diego Regional Task Force on the Homeless Annual Point-in-Time Count Services.txt',\n",
       " 'Santee Food Bank Emergency Food Supplies.txt',\n",
       " 'SBCS 2021-2022 Family Violence Treatment Program.txt',\n",
       " 'SBCS_CV - Emergency Domestic Violence Services_text.txt',\n",
       " 'South Bay Community Services Tenant Based Rental Assistance (1).txt',\n",
       " 'South Bay Community Services Tenant Based Rental Assistance.txt',\n",
       " 'St. Vincent de Paul Village Temporary Housing and Services.txt',\n",
       " 'The Salvation Army     Supportive Service.txt',\n",
       " 'Urban_Corps_of_San_Diego_County__2019.txt',\n",
       " 'Womens_Resource_Center__2018-01-23_.txt',\n",
       " 'Women_s_Resource_Center_2019.txt']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Filters out files in the largeFiles list that weren't able to be tested due to token size or that were skipped and stores in new variable txt_csvfile.\n",
    "'''\n",
    "\n",
    "filenames=[]\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "folder_path = os.path.join(current_directory, 'all_text_docs')\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name not in (largeFiles):\n",
    "         filenames.append(file_name)\n",
    "\n",
    "#txt_csvfile = csvfile.assign(text_id=filenames)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e58c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Outputs a dataframe that shows outputs for the files via testing data and the manually collected data aligned by text_id so you can see where\n",
    "there are errors.\n",
    "'''\n",
    "merged = pd.merge(new_ml, txt_csvfile, on='text_id', how='outer')\n",
    "merged = merged.dropna(thresh=merged.shape[1] - 2)\n",
    "merged['Amount_x'] = merged['Amount_x'].astype(float)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prints out accuracy for each invidiual category to show where improvement needs to be made for finetuning.\n",
    "'''\n",
    "\n",
    "# Calculate accuracy rate for each column\n",
    "accuracy_rates = {}\n",
    "\n",
    "# Compare 'Grantor' columns\n",
    "grantor_accuracy = np.where(merged['Grantor_x'] == merged['Grantor_y'], 1, 0)\n",
    "accuracy_rates['Grantor'] = sum(grantor_accuracy) / len(merged)\n",
    "\n",
    "# Compare 'Grantee_x' and 'Grantee_y' columns\n",
    "grantee_accuracy = np.where(merged['Grantee_x'] == merged['Grantee_y'], 1, 0)\n",
    "accuracy_rates['Grantee'] = sum(grantee_accuracy) / len(merged)\n",
    "\n",
    "# Compare 'Program_x' and 'Program_y' columns\n",
    "program_accuracy = np.where(merged['Program_x'] == merged['Program_y'], 1, 0)\n",
    "accuracy_rates['Program'] = sum(program_accuracy) / len(merged)\n",
    "\n",
    "# Compare 'Date' and 'Start' columns\n",
    "date_accuracy = np.where(merged['Date'] == merged['Start'], 1, 0)\n",
    "accuracy_rates['Date'] = sum(date_accuracy) / len(merged)\n",
    "\n",
    "# Compare 'EndDate' and 'Stop' columns\n",
    "enddate_accuracy = np.where(merged['EndDate'] == merged['Stop'], 1, 0)\n",
    "accuracy_rates['EndDate'] = sum(enddate_accuracy) / len(merged)\n",
    "\n",
    "# Compare 'Amount_x' and 'Amount_y' columns\n",
    "amount_accuracy = np.where(merged['Amount_x'] == merged['Amount_y'], 1, 0)\n",
    "accuracy_rates['Amount'] = sum(amount_accuracy) / len(merged)\n",
    "\n",
    "# Compare 'Funding Source_x' and 'Funding Source_y' columns\n",
    "funding_accuracy = np.where(merged['Funding Source_x'] == merged['Funding Source_y'], 1, 0)\n",
    "accuracy_rates['Funding Source'] = sum(funding_accuracy) / len(merged)\n",
    "\n",
    "# Print the accuracy rates\n",
    "for column, accuracy in accuracy_rates.items():\n",
    "    print(f\"Accuracy rate for '{column}': {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aecb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f8e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
